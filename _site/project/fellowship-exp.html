<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<!-- Page Info -->
	<link rel="shortcut icon" href="">
	<title>My experience as a ML fellow for fellowship.ai – Sanket Thakur</title>
	<meta name="description" content="">

	<!-- Twitter Card -->
	<meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:title" content="My experience as a ML fellow for fellowship.ai – Sanket Thakur">
	<meta name="twitter:description" content="">
	<meta name="twitter:image:src" content="http://localhost:4000">

	<!-- Facebook OpenGraph -->
	<meta property="og:title" content="My experience as a ML fellow for fellowship.ai – Sanket Thakur" />
	<meta property="og:description" content="" />
	<meta property="og:image" content="http://localhost:4000" />

	<!-- Styles -->
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="/css/style.css">
</head>

<body>

	<header class="header">
	<div class="header-image header-image--on" style="background-image: url();"></div>
	<div class="header-image"></div>

	<div class="header-overlay"></div>

	<div class="header__content">

		
		<a href="/about" class="header__title">
			Sanket Thakur
		</a>
		
		


		<p class="header__tagline">PhD candidate, Computer Vision. Gamer.</p>

		<div class="menu">
			<button class="menu__toggle js-menu-toggle" onclick="toggleMenuWrap();">
				Menu <div class="menu__toggle__icon"><span></span></div>
			</button>
			<div id="menu_wrap" class="menu__wrap mobile-hidden">
				<ul class="menu__list">
					
					<li class="menu__list__item">
						<a href="/" class="menu__list__item__link">Posts</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/pap/index.html" class="menu__list__item__link">Pap Series</a>
					</li>
					
				</ul>
				<ul class="socials">
	
	
	
	
	<li class="socials__item">
		<a href="https://twitter.com/sanketsans97" target="_blank" class="socials__item__link" title="Twitter">
			
				<svg class="svg-inline--fa fa-twitter fa-w-16" aria-hidden="true" data-prefix="fab" data-icon="twitter" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
			
		</a>
	</li>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<li class="socials__item">
		<a href="https://github.com/sanketsans" target="_blank" class="socials__item__link" title="Github">
			
				<svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
			
		</a>
	</li>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
</ul>
			</div>
			<script>
				function toggleMenuWrap() {
					if ( document.body.classList.contains( 'menu--open' ) ) {
						document.body.classList.remove( 'menu--open' )
					} else {
						document.body.classList.add( 'menu--open' )
					}
				}
			</script>
		</div>

	</div>

</header>

	<div class="page">
		<div class="page__content">
			<section class="intro">
	<div class="wrap">
		<h1>My experience as a ML fellow for fellowship.ai</h1>
		<p></p>
	</div>
</section>

<section class="single">
	<div class="wrap">
		<p><a href="https://fellowship.ai"><b>Fellowship.Ai</b></a> is a four months long <b>“unpaid”</b> fellowship on various machine learning topics. The program is 100 % remote,
and anyone can apply for it. (PS: Keep reading, if you should or not!). You can apply directly by submitting your resume, but if you complete one of the challenges mentioned on the website - you tend to increase your chances for getting to the interviews.
The challenges are focused on different machine learning topics such as image segmentation, Natural Language Processing (NLP),
One-Shot learning etc.</p>

<p>I applied for the second cohort of 2020 (Sept - Dec ‘20). I worked on the challenge problem of Image segmentation using a U-net
model. You can read more about the project here - <a href="https://github.com/sanketsans/Image-Matting-U-Net"> <b> Image Matting with U-Net </b></a>. On submitting the project, I got an interview call within next 2 days.
The interview was fairly easily and mostly focused on basic of ML knowledge like F1 score, Confusion matrix, etc. and some
intermediate python programming.</p>

<p>The program started with an orientation of all the accepted fellows for the cohort. You are free to choose a project based on your
choice. Most of the projects during my term was either done in partnership with other companies such as Levis or GE or very new
projects ( you will be the first to contribute to it ). Each project has about 5-6 fellows working on it. There are no mentors as such.</p>

<h2 id="rolling-with-my-crew">Rolling with my crew</h2>

<p>I was initially working on an <b><i> ‘Emotion Detection’ </i></b> project - where based on the video frames you have to classify if the person
in the zoom meeting is engaged, non-engaged, animated or distracted. For the first month, we spent collecting the dataset from
various internet scrapes. We were also provided with screenshot of internal zoom meeting. But the manual labelling has to be done
on our own - which was indeed very boring task. If you are interested in such kind of project, you can start with some of the good
dataset provided by kaggle - <a href="https://www.kaggle.com/c/mp18-eye-gaze-estimation/data"><b>Eye Gaze Estimation</b></a>, <a href="https://www.kaggle.com/kmader/biwi-kinect-head-pose-database"><b>BIWI Kinect head pose</b></a>.</p>

<div align="center" class="img-container">
    <img src="/img/fellow_exp/emotion_classes.png" width="512" height="512" border="1px" alt="emotion_classes" class="center" />
    <figcaption>Emotion Classes</figcaption>
</div>

<p>I worked on creating a pipeline for the system. The input images were resized to 128x128 pixels.</p>

<h2 id="two-stage-pipeline-">Two stage pipeline :</h2>

<li>The input is passed through first stage of the pipeline – where it identifies external entities such as phone, dog etc in the frame. The selected identities helps to understand other objects in the frame. It uses transfer learning method with pre trained model ie. No Learning happens at this stage of the pipeline.</li>

<li>After the first stage, when the identities are identified. The input image is simplified down the pipeline by cropping the face in the frame.
Then the cropped portion is sent to the classifier to be classified into 3 classes : Engaged, Non-engaged and Animated.</li>

<p>If other entities are found from the first stage of the pipeline and is classified as non-engaged by the classifier – then it is regarded as Distracted.</p>

<p><b>- - - -</b></p>

<p>I was moved to an another project since most of team member expressed interest to work on other projects. Later, I was working
on identifying <b><i> ‘Fridge Food Type Detection’ </i></b>. The project sounds easy but is very difficult to model.
First, you don’t have a good pool of images to generate a high quality dataset. Second, identifying identifying individual food
items is a daunting task, since objects are placed so close to each other in a fridge - it is hard to distinguish each of them.
Here, our major work was to generate synthetic dataset using Generative Adversarial Networks(GANs).
GANs have been pretty good lately is generating real-life like images of human faces. &lt;show some of the results.</p>

<p>But, it turns out they are not so good at generating other objects. Before joining the group, other have already worked on using StyleGAN-2 by NVIDIA<link /> to generate synthetic in-domain images. The initial dataset was built using a member’s fridge’s
in-built camera images and web scraping. Now, directly using GANs on the preliminary dataset was not successful since there were not many images. So, instead synthetic images were generated to transform them to in-domain images.
To do so, a blender script was used to randomly place 3D-objects such as bottles, veggies etc. in a fridge 3D model(3D scene generation) and jpg images were produced form the front. Reference - <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/ACVR/Koporec_Deep_Learning_Performance_in_the_Presence_of_Significant_Occlusions_-_ICCVW_2019_paper.pdf"><b>Gregor et. al ICCV ‘19 ()</b></a>.</p>

<div align="center" class="img-container">
    <img src="/img/fellow_exp/blender_image_0.jpg" alt="synthetic" width="256" height="256" />
    <figcaption>synthetic images</figcaption>
</div>

<p>I implemented a Pix2Pix GAN method to create a mapping of synthetic images(from Blender) to generate in-domain images. Though Pix2Pix GAN<link /> is a paired GAN approach and we did not have pair of synthetic and in-domain fridge images. Instead, I created
random pairs and fed it to a Pix2Pix GAN. After 200 epochs on about 1200 image pairs, results are still not convincing. You can
check out the project here - <a href="https://github.com/sanketsans/Pix-2-Pix-GAN"><b>Pix2Pix GAN</b></a>.</p>

<figure>
<img src="/img/fellow_exp/my_pix2pix_result.png" alt="results" style="width:100%" />
<figcaption align="centre">My results with Pix2Pix</figcaption>
</figure>

<p>Meanwhile, I started my Phd in November ‘20, and due to hectic schedule I had to focus more time to my PhD from December.
But, there are appreciable results using CycleGAN.
why so ? -</p>
<li>cyclic loss of the images might lead to a better mapping.</li>
<li>unpaired approach </li>

<p>You can read the entire paper here: <a href="https://www.launchpad.ai/blog/the-usage-of-cyclegan-for-image-translation-to-increase-the-size-of-fridge-food-types-dataset"><b>The Usage of CycleGAN for Image Translation to Increase the Size of Fridge Food Types Dataset</b></a></p>

<h2 id="the-good-the-bad-and-neutral">The Good, the Bad and Neutral:</h2>

<h3 id="the-good-">The Good :</h3>

<li>There are "mostly" regular reading session, where someone from the fellowship presents a paper which can help to stay updated
with current ML research.</li>
<li> You will working on real-world projects with an inter-disciplinary team from around the world.</li>
<li> Also, the fellowship provide an opportunity to regular performers to join them full-time or get a job at one of the partner companies. Did I mention one of my team member got an internship at Nike ML group and few others at Levis.</li>

<h3 id="the-bad-">The Bad :</h3>

<li>There are too many meeting. Group meeting, meeting with the co-founder, demos, etc. etc.</li>
<li>The program is UNPAID - which is a bummer. I'd recommend it highly to those who are either looking for a switch in your career or a final year student(who is done with the internship) or like me who has time before starting you higher education to apply for it.</li>
<li>Time Differences: Meetings are at quite unusual time at night for someone in Asia/Pacific region.</li>

<h3 id="neutral-bonus-">Neutral (Bonus) :</h3>

<p>Job offers from partner companies are mostly confined to US residents. But there were externships available from the fellowship to fellows everywhere.</p>

<h2 id="verdict-">Verdict :</h2>

<p>Fellowship does provide a platform for those intermediate in their learning curve of Machine Learning. Since, the program is unpaid, all the fellows(I met), were not working elsewhere full-time. So, I think if you are looking to either switch your career in an ML field or final year student(not the internship) - this will be a great opportunity to learn from real-world projects and potentially get job offers.</p>

		
			<script src="  https://unpkg.com/showdown/dist/showdown.min.js"></script>
<script>
const GH_API_URL = 'https://api.github.com/repos/sanketsans/sanketsans.github.io/issues/2/comments?per_page=100;' //'?client_id=&client_secret='

let request = new XMLHttpRequest();
request.open( 'GET', GH_API_URL, true );
request.onload = function() {
	if ( this.status >= 200 && this.status < 400 ) {
		let response = JSON.parse( this.response );

		for ( var i = 0; i < response.length; i++ ) {
			document.getElementById( 'gh-comments-list' ).appendChild( createCommentEl( response[ i ] ) );
		}

		if ( 0 === response.length ) {
			document.getElementById( 'no-comments-found' ).style.display = 'block';
		}
	} else {
		console.error( this );
	}
};

function createCommentEl( response ) {
	let user = document.createElement( 'a' );
	user.setAttribute( 'href', response.user.url.replace( 'api.github.com/users', 'github.com' ) );
	user.classList.add( 'user' );

	let userAvatar = document.createElement( 'img' );
	userAvatar.classList.add( 'avatar' );
	userAvatar.setAttribute( 'src', response.user.avatar_url );

	user.appendChild( userAvatar );

	let commentLink = document.createElement( 'a' );
	commentLink.setAttribute( 'href', response.html_url );
	commentLink.classList.add( 'comment-url' );
	commentLink.innerHTML = '#' + response.id + ' - ' + response.created_at;

	let commentContents = document.createElement( 'div' );
	commentContents.classList.add( 'comment-content' );
	commentContents.innerHTML = response.body;
	// Progressive enhancement.
	if ( window.showdown ) {
		let converter = new showdown.Converter();
		commentContents.innerHTML = converter.makeHtml( response.body );
	}

	let comment = document.createElement( 'li' );
	comment.setAttribute( 'data-created', response.created_at );
	comment.setAttribute( 'data-author-avatar', response.user.avatar_url );
	comment.setAttribute( 'data-user-url', response.user.url );

	comment.appendChild( user );
	comment.appendChild( commentContents );
	comment.appendChild( commentLink );

	console.log(comment)
	return comment;
}
request.send();
</script>

<hr>

<div class="github-comments">
	<h2>Comments</h2>
	<ul id="gh-comments-list"></ul>
	<p id="no-comments-found">No comments found for this article. </p>
	<p id="leave-a-comment">Join the discussion for this article on <a href="https://github.com/sanketsans/sanketsans.github.io/issues/2">this ticket</a>. Comments appear on this page instantly.</p>
</div>

		
	</div>
</section>

		</div>
	</div>

	<footer class="footer">

	<div class="footer__copyright">
		<span>© 2021 Sanket Thakur</span>
	</div>

</footer>
<!-- href="https://github.com/sponsors/aristath" -->
<a id="donate-sticky" ><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M13 20h-7c-2.174-3.004-4-6.284-4-12h15c0 5.667-1.88 9.089-4 12zm5.119-10c-.057.701-.141 1.367-.252 2h1.549c-.449 1.29-1.5 2.478-2.299 2.914-.358 1.038-.787 1.981-1.26 2.852 3.275-1.143 5.847-4.509 6.143-7.766h-3.881zm-1.119 12h-15v2h15v-2zm-3.06-19.614c-.416 1.702-3.07 2.477-3.983 4.614-.088-1.846 1.107-3.031 1.75-3.93 1.045-1.465-.537-2.267-1.633-1.171-.188.187-.38.435-.573.756-.193-.322-.386-.57-.573-.757-1.089-1.09-2.664-.294-1.658 1.137.635.903 1.863 2.095 1.775 3.965-.914-2.137-3.567-2.912-3.984-4.614-.355-1.445.928-2.386 2.29-2.386.793 0 1.613.32 2.15 1.045.537-.725 1.357-1.045 2.15-1.045 1.362 0 2.644.941 2.289 2.386z"/></svg> Like what you read? It takes lots of coffee!</a>
<style>#donate-sticky{background:#2E7D32;color:#fff!important;padding:.5rem;position:fixed;bottom:0;right:0;text-decoration:none;font-size:1rem;opacity:.1;transition:.2s;right:0;width:2rem;height:2.5rem;overflow:hidden;text-align:right;}#donate-sticky:hover,#donate-sticky:focus,#donate-sticky:active{opacity:1;width:100%;}#donate-sticky svg{width:1rem;height:1rem;fill:#fff;margin-right:1rem;}</style>

</body>
</html>
