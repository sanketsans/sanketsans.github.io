---
title: Ciao
subtitle: /tʃaʊ/
description: PhD candidate, Computer Vision. Gamer.
featured_image: /img/sanket.jpg
---

I'm Sanket, an aspiring researcher working on Multi Modal Deep learning with a focus on egocentric vision. I am final year PhD student at PAVIS, Italian Institute of Technology under the supervision of Dr. Alessio Del Bue. During my research, I primiarily focus on social interaction analysis for first person videos. 

Previously, I have worked with <a href="https://www.bell-labs.com/our-research/future-x-vision/"><b>Nokia Bell Labs</b></a> ,  <a href="https://trezi.com"><b>SmartVizx</b></a> , <a href="https://www.ey.com/en_gl/wavespace/trivandrum"><b>Ernst and Young</b></a>  with their research teams. Besides, I had two startups during my college and filed two provisional patents. I have also been an active participant in technical communities and presented multiple technical talks and workshops at various level(s).

Passionate about ***Video understanding***, ***object detection*** & ***multimodal learning.***
<font color="red">PS : On the lookout for full-time roles as MLE / Applied Scientist. </font>


***Checkout my latest podcast !***
<div style="display: flex; justify-content: center;">
    <iframe src="https://open.spotify.com/embed/show/7bnalsMIGlbmQYZtqrf36d?t=0" width="80%" height="35%" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>
</div>



Hit me up and lets make another ***podcast.***

## News [Updates]:

##### Papers:

***Leveraging Next-Active Objects for Short-Term Anticipation in Egocentric Videos** <br>
    **Thakur S.**, Beyan C., Morerio P., Murino V., Del Bue A. <br>
    WACV '24 <br>
    [<span style="color: #249eda;">Project Page</span>](leverage-next-active-object-action-anticipation.html), [<span style="color: #6cc644;">Paper</span>](https://arxiv.org/abs/2308.08303)
    <!-- [<span style="color: #249eda;">Project Page</span>](anticipating-next-active-object-egocentric.html), [<span style="color: #6cc644;">Paper</span>](https://arxiv.org/abs/2302.06358) -->


***Guided Attention for Next Active Object@ EGO4D STA Challenge** <br>
CVPRW'23 <br>
    **Thakur S.**, Beyan C., Morerio P., Murino V., Del Bue A. <br> 
    [<span style="color: #6cc644;">CVPRW Paper </span>](https://arxiv.org/abs/2305.16066) - **GANOv2**, [<span style="color: #575453;">Code, GANOv2 - CVPR23 submission</span>](https://github.com/sanketsans/ganov2) <br>
    **Winner CVPR23 EGO4D STA challenge** &#9733; <br>
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/guided-attention-for-next-active-object-ego4d/short-term-object-interaction-anticipation-on)](https://paperswithcode.com/sota/short-term-object-interaction-anticipation-on?p=guided-attention-for-next-active-object-ego4d)

***Enchancing Next-Active-Object based Egocentric Action Anticipation with Guided Attention** <br>
ICIP'23 <br>
    **Thakur S.**, Beyan C., Morerio P., Murino V., Del Bue A. <br> 
    [<span style="color: #249eda;">Project Page</span>](guided-attention-egocentric.html), [<span style="color: #6cc644;">Paper</span>](https://arxiv.org/abs/2305.12953) <br>

***Anticipating Next Active Object for egocentric videos** <br>
    **Thakur S.**, Beyan C., Morerio P., Murino V., Del Bue A. <br>
    **Journal Review** <br>
    [<span style="color: #249eda;">Project Page</span>](anticipating-next-active-object-egocentric.html), [<span style="color: #6cc644;">Paper</span>](https://arxiv.org/abs/2302.06358)

***Audio-Visual Inpainting: Reconstructing Missing Visual Information with Sound** <br>
ICASSP'23 <br>
    Sanguineti V., **Thakur S.**, Morerio P., Del Bue A., Murino V.<br>
    [<span style="color: #249eda;">Project Page</span>](audio-visual-inpainting.html), [<span style="color: #6cc644;">Paper</span>](https://ieeexplore.ieee.org/abstract/document/10095447)


***Predicting Gaze from Egocentric Social Interaction Videos and IMU Data** <br>
ACM ICMI'21 <br>
    **Thakur S.**, Beyan C., Morerio P., Del Bue A. <br>
    [<span style="color: #249eda;">Project Page</span>](predicting-gaze-egocentric.html), [<span style="color: #6cc644;">Paper</span>](https://dl.acm.org/doi/abs/10.1145/3462244.3479954), [<span style="color: #575453;">Code</span>](https://github.com/IIT-PAVIS/MultimodalGaze) 
    


    




    


<!-- <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30"><a xlink:href="https://dl.acm.org/doi/abs/10.1145/3462244.3479954"><path d="M11.363 2c4.155 0 2.637 6 2.637 6s6-1.65 6 2.457v11.543h-16v-20h7.363zm.826-2h-10.189v24h20v-14.386c0-2.391-6.648-9.614-9.811-9.614zm4.811 13h-2.628v3.686h.907v-1.472h1.49v-.732h-1.49v-.698h1.721v-.784zm-4.9 0h-1.599v3.686h1.599c.537 0 .961-.181 1.262-.535.555-.658.587-2.034-.062-2.692-.298-.3-.712-.459-1.2-.459zm-.692.783h.496c.473 0 .802.173.915.644.064.267.077.679-.021.948-.128.351-.381.528-.754.528h-.637v-2.12zm-2.74-.783h-1.668v3.686h.907v-1.277h.761c.619 0 1.064-.277 1.224-.763.095-.291.095-.597 0-.885-.16-.484-.606-.761-1.224-.761zm-.761.732h.546c.235 0 .467.028.576.228.067.123.067.366 0 .489-.109.199-.341.227-.576.227h-.546v-.944z"/></a></svg> -->
<!-- </svg> -->

<!-- <p>Accepted at ACM ICMI '21</p> -->

<!-- ##### Summer School: -->

<!-- ***Accepted into CIFAR Summer School '21***
<p>May 20th '21</p> -->

##### [Other]:

***Poster Award, Synapse AI symposium 2023: [(Poster)](https://drive.google.com/file/d/19a2UdN0CxnEjR0jqVfHCkArlsXOJnV23/view?usp=sharing)***, Sept '23

***Technical Talk at Dolby Labs : [Next-Active-Objects for egocentric videos](https://drive.google.com/file/d/1unUyanZZ-BkZ-pK3Vg80Zn_ys78WrQHJ/view?usp=sharing)***, Sept '23

***Visiting [CSIC-IRI](https://www.iri.upc.edu)(UPC), Barcelona to work with [Mariella Dimiccoli](https://www.iri.upc.edu/staff/mdimiccoli)***, May '22
<p></p>

***Invited Technical Talk at SVNIT,India : [Egocentric Video Understanding](https://drive.google.com/file/d/1gBB2ICuQB3rrcuz4fyKPIxbBv3S6cka_/view?usp=sharing)*** , Aug '22
<p></p>

***Attended [VS3'22 Summer school](http://cmp.felk.cvut.cz/summerschool2022/index.html)*** , July '22 <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M20.5 13c-1.932 0-3.5 1.567-3.5 3.5s1.568 3.5 3.5 3.5 3.5-1.567 3.5-3.5-1.568-3.5-3.5-3.5zm1.5 4h-1v1h-1v-1h-1v-1h1v-1h1v1h1v1zm-13.001-5.9c0 1.692-.766 2.9-1.206 3.9h-1.397c.227-1 1.954-3.415 1.021-4.982-.55-.923-2.272-.924-2.819-.015-.507.841-.24 2.417.712 4.215.518.978.374 1.734.162 2.197-.406.889-1.303 1.317-2.316 1.612-2.01.588-1.825.055-1.825 1.973h-1.329l-.002-.618c0-1.262.099-1.989 1.59-2.333 1.719-.397 3.319-.745 2.545-2.209-2.361-4.457-.627-6.84 1.866-6.84 1.687 0 2.998 1.09 2.998 3.1zm5.691 1.395c.607 1.146.447 2.016.206 2.543-.66 1.445-2.472 1.863-4.39 2.305-1.252.29-1.172.588-1.172 2.657h-1.331l-.003-.825c0-1.681.132-2.652 2.119-3.111 2.293-.53 4.427-.994 3.394-2.946-3.147-5.941-.835-9.118 2.488-9.118 3.164 0 5.337 2.879 3.041 8h-1.483c1.159-2.325 1.428-4.326.708-5.533-.902-1.517-3.617-1.509-4.512-.022-.768 1.273-.426 3.478.935 6.05z"/></svg>
<p></p>

***Accepted for [ELLIS Doctoral symposium '21]()*** , September '21 <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M20.5 13c-1.932 0-3.5 1.567-3.5 3.5s1.568 3.5 3.5 3.5 3.5-1.567 3.5-3.5-1.568-3.5-3.5-3.5zm1.5 4h-1v1h-1v-1h-1v-1h1v-1h1v1h1v1zm-13.001-5.9c0 1.692-.766 2.9-1.206 3.9h-1.397c.227-1 1.954-3.415 1.021-4.982-.55-.923-2.272-.924-2.819-.015-.507.841-.24 2.417.712 4.215.518.978.374 1.734.162 2.197-.406.889-1.303 1.317-2.316 1.612-2.01.588-1.825.055-1.825 1.973h-1.329l-.002-.618c0-1.262.099-1.989 1.59-2.333 1.719-.397 3.319-.745 2.545-2.209-2.361-4.457-.627-6.84 1.866-6.84 1.687 0 2.998 1.09 2.998 3.1zm5.691 1.395c.607 1.146.447 2.016.206 2.543-.66 1.445-2.472 1.863-4.39 2.305-1.252.29-1.172.588-1.172 2.657h-1.331l-.003-.825c0-1.681.132-2.652 2.119-3.111 2.293-.53 4.427-.994 3.394-2.946-3.147-5.941-.835-9.118 2.488-9.118 3.164 0 5.337 2.879 3.041 8h-1.483c1.159-2.325 1.428-4.326.708-5.533-.902-1.517-3.617-1.509-4.512-.022-.768 1.273-.426 3.478.935 6.05z"/></svg>
<p></p>

***Website Chair, [ETRA '22](http://etra.acm.org/2022/index.html)*** , July '21 <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M22 3.2c0-.663-.537-1.2-1.2-1.2h-17.6c-.663 0-1.2.537-1.2 1.2v11.8h20v-11.8zm-2 9.8h-16v-9h16v9zm2 3h-20c-.197.372-2 4.582-2 4.998 0 .522.418 1.002 1.002 1.002h21.996c.584 0 1.002-.48 1.002-1.002 0-.416-1.803-4.626-2-4.998zm-12.229 5l.467-1h3.523l.467 1h-4.457z"/></svg>
<p></p>


***Started PhD at [PAVIS/VGM](https://vgm.iit.it), IIT*** , November '20 <svg width="24" height="24" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd"><path d="M24 21h-3l1-3h1l1 3zm-12.976-4.543l8.976-4.575v6.118c-1.007 2.041-5.607 3-8.5 3-3.175 0-7.389-.994-8.5-3v-6.614l8.024 5.071zm11.976.543h-1v-7.26l-10.923 5.568-11.077-7 12-5.308 11 6.231v7.769z"/></svg>
<!-- <p></p> -->

---------

You can find me on [Twitter](https://twitter.com/sanketsans97).  
If you're oldfashioned you can [send me an email](mailto:sanket.thakur@iit.it)

Checkout some of my <a href="https://maker.pro/profile/sanket.thakur"><b><u>VR / AR tutorials</u></b></a> from previous life
<svg xmlns="http://www.w3.org/2000/svg" width="45" height="45" viewBox="0 0 45 45"><path d="M14 20h-6v-1h6v1zm5-12h-2v1h2v-1zm-3 9h-8v1h8v-1zm8-13v15h-4v5h-16v-5h-4v-15h4v-4h16v4h4zm-18 0h12v-2h-12v2zm12 11h-12v7h12v-7zm4-9h-20v11h2v-4h16v4h2v-11zm-10 2h-7v3h7v-3zm7 2h-2v1h2v-1zm-3 0h-2v1h2v-1zm0-2h-2v1h2v-1z"/></svg>

**PS: I am still updating this site, few commits a day.**
 <!-- width="2%" height="2%" -->
<div style="margin-top:2%">
    <div style="float:left; width:4%; height:4%"><img src="/img/claim_sign.png" alt="claim_sign"></div>
    <div style="float:left; margin-left:2%">This claim is disputed.</div>
    <div style="clear: left;"/>
</div>



<div style="margin-top:2%">
    <blockquote class="twitter-tweet"><p lang="en" dir="ltr">PI: Congratulating me for submission. <br>Me : Who was still running models to get results in the last hour. <a href="https://twitter.com/hashtag/thoughtsofaphd?src=hash&amp;ref_src=twsrc%5Etfw">#thoughtsofaphd</a> <a href="https://twitter.com/hashtag/phdchat?src=hash&amp;ref_src=twsrc%5Etfw">#phdchat</a> <a href="https://t.co/jGh35e8eMA">pic.twitter.com/jGh35e8eMA</a></p>&mdash; Sanket Thakur (@sanketsans97) <a href="https://twitter.com/sanketsans97/status/1406652103880216577?ref_src=twsrc%5Etfw">June 20, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
